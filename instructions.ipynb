{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6cd194",
   "metadata": {},
   "source": [
    "## INSTRUCTIONS FOR RUNNING THE DATA GATHERING PROCESS\n",
    "Notes:\n",
    "* All file/folder references are from the main horseData folder\n",
    "* To find track abbreviations/track names, go to `equibase.com`, in the upper right select \"Tracks\" in the drop down menu and type the track name. The track abbreviation will be in the url. To find the track name from the abbreviation, enter `https://www.equibase.com/profiles/Results.cfm?type=Track&trk=<TRACK ABBREVIATION>&cy=USA`, inserting the track abbreviation after \"trk=\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acffd118",
   "metadata": {},
   "source": [
    "1. Run `~/python/scripts.py --scriptName generateDayLinks --startDate <m/d/yyyy> --endDate <m/d/yyyy>`\n",
    "\n",
    "2. Open `~/excel/dayLinksTemp.csv` and copy a chunk of links (say 50 cells) and copy them into the text box at `openmultipleurl.com`, then open all the tabs\n",
    "    * If you get an \"I am a human\" test, click the box then close the tabs and reopen from `openmultipleurl.com`\n",
    "\n",
    "3. Make sure the browser is saving html page downloads in `~/html/` and the AutoHotKey script at `~/python/scripts/saveHtmlHotkey.ahk` specifies the loop variable in line 3 to correspond to the number of tabs you opened in step 2 (e.g. 50)\n",
    "\n",
    "4. Run the AutoHotKey script at `~/python/scripts/saveHtmlHotkey.ahk` by double clicking; this \"primes\" it, then open the browser and press `ctrl+j` to activate it\n",
    "\n",
    "5. Rename the htmls just downloaded and generate links for any missed by running `~/python/scripts.py --scriptName findMissingHtmls --startDate <m/d/yyyy> --endDate <m/d/yyyy>` with the same `startDate` and `endDate` as in step 1\n",
    "    * Repeat steps 2 - 5 as needed until all dates have been downloaded (this step is necessary because the AHK script sometimes misses dates)\n",
    "\n",
    "6. (May not be necessary) For full robustness, double check that all the saved PDF tracks are in the master track name converter file by running `~/python/scripts.py --scriptName checkSavedTrackNamesInConverter`; if any are listed as missing, you can add them by using the bullet above in the Notes section about finding track names/abbreviations (NB: the name listed on the Equibase track overview page may be different from the name listed on the results PDF, e.g. \"Gillespie Fair\" vs. \"Gillespie County Fair\", etc.)\n",
    "\n",
    "7. Run `~/python/scripts.py --scriptName saveRaceUrlsFromHtml`\n",
    "\n",
    "8. Make sure the browser is set to automatically download PDF files and set the download location to an appropriate folder (e.g. `~/charts/pdfs/`)\n",
    "\n",
    "9. Open `~/excel/raceUrlsTemp.csv` and copy a chunk of links (say 50 cells) and copy them into the text box at `openmultipleurl.com`, then open all the tabs\n",
    "    * Repeat this step as needed, e.g. until all the race links are done\n",
    "\n",
    "10. Rename the downloaded PDFs and move them to a permanent folder by running `~/python/scripts.py --scriptName renameAndMovePdfs`\n",
    "\n",
    "11. Convert the PDFs to TXTs by running `~/python/scripts.py --scriptName pdf2txt`\n",
    "    * This step actually combines two steps (1. PDF -> XML, 2. XML -> TXT); you can run these individually with `~/python/scripts.py --scriptName pdf2xml` and `~/python/scripts.py --scriptName xml2txt`\n",
    "\n",
    "12. Convert the TXTs to json and update `~/outputs/entries.json` by running `~/python/scripts.py --scriptName generateAndSaveEntries`\n",
    "\n",
    "*Need a way to tell what's already in the database and only add new stuff; maybe check. Otherwise, lay out how to remove data from tables in database and add full entries.*\n",
    "\n",
    "NB: Currently there is no way to add new data to the database, so I've just been deleting everything and repopulating the databases. There are two schemas, `main` and `test`. As the names suggest, `main` is only to be altered once changes have been assessed on `test`. There are SQL scripts in `~/sql/` for creating both schemas, deleting all data from the tables in both schemas, and deleting all tables from both schemas. \n",
    "\n",
    "13. Before adding the new data to the database, remove all the old data (see note above) by running `~/python/scripts.py --scriptName deleteSchemaData --schema test`\n",
    "\n",
    "14. Populate the schema by running `~/python/scripts.py --scriptName populateSchema --schema test`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
